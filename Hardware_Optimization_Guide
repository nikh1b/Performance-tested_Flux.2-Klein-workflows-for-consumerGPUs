# Hardware Optimization Guide: Flux.2 Klein for ComfyUI

This guide provides optimized configurations and hardware requirements for running **Flux.2 Klein** models in ComfyUI (2026 Edition).

---

## üèéÔ∏è Quick Reference Table

| GPU Tier | Recommended Model | Resolution | Target VRAM |
| :--- | :--- | :--- | :--- |
| **RTX 3060 (12GB)** | 4B Distilled (FP8) | 512x512 | ~5.8 GB |
| **RTX 3070 (8GB)** | 4B Base (FP8) | 640x640 | ~7.2 GB |
| **RTX 4070 (12GB)** | 9B Distilled (FP8) | 768x768 | ~9.8 GB |
| **RTX 4090 (24GB)** | 9B Base (FP8) | 1024x1024 | ~20.5 GB |

---

## üõ†Ô∏è GPU Specific Configurations

### RTX 3060 / 3070 (Low VRAM)
To avoid Out of Memory (OOM) errors on 8GB-12GB cards, use the "Distilled" model variants.

* **Model:** `flux-2-klein-4b-fp8.safetensors`
* **Text Encoder:** Enable CPU Offloading.
    * *Effect:* Saves ~0.8GB VRAM at the cost of ~0.3s latency.
* **Sampler Settings:**
    * **Steps:** 4‚Äì10 (Peak quality for distilled models).
    * **Sampler:** `dpmpp_2m`
    * **Scheduler:** `karras`
* **Limit:** Do not exceed 512x512 resolution on 8GB cards.

### RTX 4070 / 4080 (Mid Range)
* **Model:** `flux-2-klein-base-4b-fp8.safetensors`
* **Batching:** Supports Batch Size 2 at 768x768 (~10.2GB usage).
* **Optimal Sampler:** `dpmpp_3m_sde_karras` for a balance of speed and sharp detail.

### RTX 4090 (High End)
* **Model:** `flux-2-klein-9b-fp8.safetensors`
* **Resolution:** 1024x1024 native.
* **Batching:** Supports Batch Size 4, but monitor temps closely as VRAM usage will hit ~95%.

---

## ‚öôÔ∏è Core Optimization Settings

### 1. Sampler Selection
Flux.2 Klein is optimized for Karras-based samplers.
* **For Speed:** `dpmpp_2m_karras`
* **For Quality:** `dpmpp_3m_sde_karras`
* **CFG Scale:** Keep between **3.5 and 4.0**. Higher values may cause artifacts.

### 2. Quantization (FP8 vs FP16)
* **FP8 (Recommended):** Use for almost all use cases. 99% quality retention with significantly lower VRAM footprint.
* **FP16:** Only recommended for RTX 4090 users performing professional upscaling or high-resolution training.

### 3. Thermal Management
Diffusion is hardware-intensive. Monitor your GPU using `nvidia-smi`.
* **Safe:** < 80¬∞C
* **Warning:** 80-85¬∞C (Throttling may occur)
* **Danger:** > 85¬∞C

---

## üìÇ Installation & Organization
For best performance, ensure your directory structure follows the ComfyUI standard on an **NVMe SSD**:

```text
ComfyUI/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ diffusion_models/    # Flux.2 Klein Checkpoints
‚îÇ   ‚îú‚îÄ‚îÄ text_encoders/       # Qwen_3 or T5 Encoders
‚îÇ   ‚îî‚îÄ‚îÄ vae/                 # Flux-specific VAE
üìù Troubleshooting Checklist
[ ] Slow Inference? Check if nvidia-smi shows other apps (Chrome/Discord) consuming VRAM.

[ ] Crashes on Load? Enable cpu_offload in your extra_model_paths.yaml.

[ ] Artifacts? Lower your CFG Scale to 3.5 and ensure you are using the karras scheduler.

Last Updated: January 2026
